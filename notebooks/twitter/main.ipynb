{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596581214963",
   "display_name": "Python 3.7.7 64-bit ('codenation': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import geopy\n",
    "import folium\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob as tb\n",
    "from googletrans import Translator\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = \"\"\n",
    "API_secret_key = \"\"\n",
    "Acess_token = \"\"\n",
    "Access_token_secret = \"\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_key, API_secret_key)\n",
    "auth.set_access_token(Access_token, Access_token_secret)\n",
    "\n",
    "api = tweepy.API(\n",
    "    auth, \n",
    "    wait_on_rate_limit=True, \n",
    "    wait_on_rate_limit_notify=True, \n",
    "    retry_count=5, \n",
    "    retry_delay=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "info = []\n",
    "keyword = ['covid OR covid-19 OR corona OR coronavirus OR pandemic']\n",
    "\n",
    "# tweet = token.search(q=keyword, count=10, result_type='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(\n",
    "    api.search, \n",
    "    q=keyword, \n",
    "    tweet_mode='extended', \n",
    "    rpp=1000, \n",
    "    result_type='mixed', \n",
    "    lang='en', \n",
    "    include_entities=True\n",
    ").items(1000):\n",
    "    if 'retweeted_status' in dir(tweet):\n",
    "        aux = tweet.retweeted_status.full_text\n",
    "    else:\n",
    "        aux = tweet.full_text\n",
    "\n",
    "    newtweet = aux.replace(\"\\n\", \" \")\n",
    "\n",
    "    tweets.append(newtweet)\n",
    "    info.append(tweet)\n",
    "    file = open('tweets_Keyword_covid_en_turma2.txt', 'a', -1, 'utf-8')\n",
    "    file.write(newtweet+'\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total de tweets coletados {len(info)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame(tweets, columns = ['Tweets'])\n",
    "\n",
    "tweets_df['len'] = np.array([len(tweet) for tweet in tweets])\n",
    "tweets_df['ID'] = np.array([tweet.id for tweet in info])\n",
    "tweets_df['USER'] = np.array([tweet.user.screen_name for tweet in info])\n",
    "tweets_df['userName'] = np.array([tweet.user.name for tweet in info])\n",
    "tweets_df['userLocation'] = np.array([tweet.user.location for tweet in info])\n",
    "tweets_df['Language'] = np.array([tweet.user.lang for tweet in info])\n",
    "tweets_df['Date'] = np.array([tweet.created_at for tweet in info])\n",
    "tweets_df['Source'] = np.array([tweet.source for tweet in info])\n",
    "tweets_df['Likes'] = np.array([tweet.favorite_count for tweet in info])\n",
    "tweets_df['Retweets'] = np.array([tweet.retweet_count for tweet in info])\n",
    "tweets_df['Geo'] = np.array([tweet.geo for tweet in info])\n",
    "tweets_df['Coordinates'] = np.array([tweet.coordinates for tweet in info])\n",
    "tweets_df['Place'] = np.array([tweet.place for tweet in info])\n",
    "\n",
    "tweets_df.to_csv('./tweets_Keyword_covid_en_Turma2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_max = np.max(tweets_df['Likes'])\n",
    "\n",
    "likes = tweets_df[tweets_df.Likes == likes_max].index[0]\n",
    "\n",
    "print(f'O tweet com mais curtidas é: {tweets_df['Tweets'][likes]} com {likes_max} curtidas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(tweets_df['Likes'] == likes_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_max = np.max(tweets_df['Retweets'])\n",
    "\n",
    "retweet = tweets_df[tweets_df.Retweets == retweet_max].index[0]\n",
    "\n",
    "print(f'O tweet com mais retweet é {tweets_df['Tweets'][retweet]} com {retweet_max} retweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "\n",
    "for source in tweets_df['Source']:\n",
    "    if source not in sources:\n",
    "        sources.append(source)\n",
    "\n",
    "percent = np.zeros(len(sources))\n",
    "\n",
    "for source in tweets_df['Source']:\n",
    "    for index in range(len(sources)):\n",
    "        if source == sources[index]:\n",
    "            percent[index] += 1\n",
    "            \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceDF = pd.DataFrame({'source': percent}, index=sources)\n",
    "\n",
    "sourceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_sorted = sourceDF.sort_values('source', ascending=True)\n",
    "ax = sources_sorted.source.plot(kind='barh', color='#A52A2A')\n",
    "ax.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_sorted = sourceDF.sort_values('source', ascending=True)\n",
    "ax = sources_sorted.source.plot(kind='barh', color='#B8860B')\n",
    "ax.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = None\n",
    "polarities = []\n",
    "\n",
    "for tweet in tweets_df['Tweets']:\n",
    "    analysis = tb(tweet)\n",
    "\n",
    "    polarity = analysis.sentiment.polarity\n",
    "\n",
    "    polarities.append(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative\n",
    "for tweet in tweets_df['Tweets']:\n",
    "    polarity = tb(tweet).sentiment.polarity\n",
    "\n",
    "    polarities.append(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Vetor de polaridade: ', polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Para as palavras: {keyword}\\nA média de sentimento é: {str(np.mean(polarities))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive, negative, neutral = 0, 0, 0\n",
    "\n",
    "for polarity in polarities:\n",
    "    if polarity > 0:\n",
    "        positive += 1\n",
    "    elif polarity < 0:\n",
    "        negative += 1\n",
    "    else:\n",
    "        neutral += 1\n",
    "\n",
    "pos_pct = positive * 100/len(polarities)\n",
    "neg_pct = negative * 100/len(polarities)\n",
    "neu_pct = neutral * 100/len(polarities)\n",
    "\n",
    "sentiment_label = ['Positivos', 'Negativos', 'Neutros']\n",
    "percents = [pos_pct, neg_pct, neu_pct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart = pd.Series(percents, index=sentiment_label, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart.plot.pie(fontsize=12, autopct='%.2f', figsize=(5, 5), labels=pie_chart.index, title='Análise de Sentimento Tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando matplotlib\n",
    "patchets, text = plt.pie(percents, startangle=90)\n",
    "plt.legend(patches, sentiments, loc='best')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapa localizador de Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## libs folium e geo\n",
    "locator = Nominatim(user_agent='TweeterSentiments')\n",
    "exemplo = locator.geocode('Belo Horizonte')\n",
    "exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = []\n",
    "longitude = []\n",
    "\n",
    "for user_location in tweets_df['User Location']:\n",
    "    try:\n",
    "        location = geolocator.geocode(user_location)\n",
    "        latitude.append(location.latitude)\n",
    "        longitude.append(location.longitude)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "coordenadas = np.column_stack((latitude, longitude))\n",
    "\n",
    "mapa = folium.Map(zoom_start=3)\n",
    "mapa.add_child(plugins.HeatMap(coordenadas))\n",
    "mapa.save('Mapa_Calor_covid_en_Turma2.html')\n",
    "mapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuvem de palavras // wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "#import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ' '.join(tweets_df['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_clean = \" \".join([\n",
    "    word for word in words.split()\n",
    "        if 'https' not in word \n",
    "            and not word.startswith('@') \n",
    "            and not word.startswith('#')\n",
    "            and word != 'RT'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "wc = WordCloud(\n",
    "    min_font_size=10,\n",
    "    max_font_size=300,\n",
    "    background_color='white',\n",
    "    mode='RGB',\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    normalize_plurals=True\n",
    ").generate(words_clean)\n",
    "\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig('covid_cloud_pt_Turma2.png', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "new_words = []\n",
    "\n",
    "with open(\"stopwords_pt.txt\", 'r') as f:\n",
    "    [new_words.append(word) for line in f for word in line.split()]\n",
    "\n",
    "new_stopwords = stopwords.union(new_words)\n",
    "\n",
    "words = ' '.join(tweets_df['Tweets'])\n",
    "\n",
    "words_clean = \" \".join([\n",
    "    word for word in words.split()\n",
    "        if 'https' not in word \n",
    "            and not word.startswith('@') \n",
    "            and not word.startswith('#')\n",
    "            and word != 'RT'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "wc = WordCloud(\n",
    "    min_font_size=10,\n",
    "    max_font_size=300,\n",
    "    background_color='white',\n",
    "    mode='RGB',\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    normalize_plurals=True\n",
    ").generate(words_clean)\n",
    "\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig('covid_cloud_pt_Turma2.png', dpi=300);"
   ]
  }
 ]
}